<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebLLM Static Chat</title>

    <!-- Required headers for WebLLM -->
    <meta http-equiv="Cross-Origin-Embedder-Policy" content="require-corp">
    <meta http-equiv="Cross-Origin-Opener-Policy" content="same-origin">

    <link rel="stylesheet" href="assets/styles/popup.css">
</head>

<body>
    <div class="container" style="min-width: 600px; min-height: 1000px;">
        <div class="header">
            <h1>ü§ñ WebLLM Chat</h1>
            <p>Local AI Chat - Runs entirely in your browser</p>
        </div>
        
        <div class="disclaimer">
            ‚ö†Ô∏è First time setup may download up to 2GB of model data. Requires modern browser with WebGPU support.
        </div>
        
        <div class="model-selector">
            Model: 
            <select id="modelSelect">
                <option value="Llama-3.2-1B-Instruct-q4f32_1-MLC">Llama 3.2 1B (Fast, ~800MB)</option>
                <option value="Llama-3.2-3B-Instruct-q4f32_1-MLC">Llama 3.2 3B (Better, ~1.8GB)</option>
                <option value="Phi-3.5-mini-instruct-q4f16_1-MLC">Phi 3.5 Mini (Compact, ~2.2GB)</option>
            </select>
            <button id="loadModelBtn">Load Model</button>
        </div>
        
        <div class="status loading" id="status">
            Select and load a model to start chatting
        </div>
        
        <div class="chat-container">
            <div class="messages" id="messages">
                <div class="message assistant">
                    üëã Welcome to WebLLM Chat! This AI runs completely in your browser - no data is sent to any server. 
                    <br><br>
                    <strong>To get started:</strong>
                    <br>1. Select a model above
                    <br>2. Click "Load Model" 
                    <br>3. Wait for download to complete
                    <br>4. Start chatting!
                </div>
            </div>
            
            <div class="loading-indicator" id="loadingIndicator">
                <div class="dots">
                    <div class="dot"></div>
                    <div class="dot"></div>
                    <div class="dot"></div>
                </div>
            </div>
        </div>
        
        <div class="input-area">
            <div class="input-container">
                <input 
                    type="text" 
                    id="messageInput" 
                    placeholder="Load a model first to start chatting..." 
                    disabled
                >
                <button id="sendButton" disabled>Send</button>
            </div>
        </div>
    </div>
</body>

<script type="module" src="popup.js"></script>

</html>