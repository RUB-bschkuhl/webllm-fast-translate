<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebLLM Static Chat</title>
    
    <!-- Required headers for WebLLM -->
    <meta http-equiv="Cross-Origin-Embedder-Policy" content="require-corp">
    <meta http-equiv="Cross-Origin-Opener-Policy" content="same-origin">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .container {
            width: 90%;
            max-width: 800px;
            height: 80vh;
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(90deg, #4facfe, #00f2fe);
            color: white;
            padding: 20px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 24px;
            margin-bottom: 5px;
        }
        
        .header p {
            opacity: 0.9;
            font-size: 14px;
        }
        
        .status {
            padding: 15px 20px;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
            font-size: 14px;
            font-weight: 500;
        }
        
        .status.loading { color: #ffc107; }
        .status.ready { color: #28a745; }
        .status.error { color: #dc3545; }
        
        .chat-container {
            flex: 1;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }
        
        .messages {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }
        
        .message {
            max-width: 70%;
            padding: 12px 16px;
            border-radius: 18px;
            word-wrap: break-word;
            line-height: 1.4;
        }
        
        .message.user {
            align-self: flex-end;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
        }
        
        .message.assistant {
            align-self: flex-start;
            background: #f1f3f4;
            color: #333;
        }
        
        .input-area {
            padding: 20px;
            border-top: 1px solid #e9ecef;
            background: white;
        }
        
        .input-container {
            display: flex;
            gap: 10px;
            align-items: center;
        }
        
        #messageInput {
            flex: 1;
            padding: 12px 16px;
            border: 2px solid #e9ecef;
            border-radius: 25px;
            outline: none;
            font-size: 16px;
            transition: border-color 0.3s;
        }
        
        #messageInput:focus {
            border-color: #667eea;
        }
        
        #sendButton {
            padding: 12px 20px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-weight: 600;
            transition: transform 0.2s;
        }
        
        #sendButton:hover:not(:disabled) {
            transform: translateY(-2px);
        }
        
        #sendButton:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }
        
        .loading-indicator {
            display: none;
            align-self: flex-start;
            padding: 12px 16px;
            background: #f1f3f4;
            border-radius: 18px;
            color: #666;
        }
        
        .dots {
            display: inline-flex;
            gap: 4px;
            align-items: center;
        }
        
        .dots::before {
            content: 'Thinking';
            margin-right: 8px;
        }
        
        .dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #666;
            animation: pulse 1.4s infinite both;
        }
        
        .dot:nth-child(1) { animation-delay: 0s; }
        .dot:nth-child(2) { animation-delay: 0.2s; }
        .dot:nth-child(3) { animation-delay: 0.4s; }
        
        @keyframes pulse {
            0%, 80%, 100% { opacity: 0.3; }
            40% { opacity: 1; }
        }
        
        .model-selector {
            padding: 10px 20px;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
            font-size: 12px;
        }
        
        .model-selector select {
            margin-left: 10px;
            padding: 4px 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 12px;
        }
        
        .disclaimer {
            padding: 10px 20px;
            background: #fff3cd;
            border-bottom: 1px solid #ffeaa7;
            font-size: 12px;
            color: #856404;
            text-align: center;
        }

        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                width: 95%;
                height: 90vh;
            }
            
            .message {
                max-width: 85%;
            }
            
            .header h1 {
                font-size: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ WebLLM Chat</h1>
            <p>Local AI Chat - Runs entirely in your browser</p>
        </div>
        
        <div class="disclaimer">
            ‚ö†Ô∏è First time setup may download up to 2GB of model data. Requires modern browser with WebGPU support.
        </div>
        
        <div class="model-selector">
            Model: 
            <select id="modelSelect">
                <option value="Llama-3.2-1B-Instruct-q4f32_1-MLC">Llama 3.2 1B (Fast, ~800MB)</option>
                <option value="Llama-3.2-3B-Instruct-q4f32_1-MLC">Llama 3.2 3B (Better, ~1.8GB)</option>
                <option value="Phi-3.5-mini-instruct-q4f16_1-MLC">Phi 3.5 Mini (Compact, ~2.2GB)</option>
            </select>
            <button id="loadModelBtn">Load Model</button>
        </div>
        
        <div class="status loading" id="status">
            Select and load a model to start chatting
        </div>
        
        <div class="chat-container">
            <div class="messages" id="messages">
                <div class="message assistant">
                    üëã Welcome to WebLLM Chat! This AI runs completely in your browser - no data is sent to any server. 
                    <br><br>
                    <strong>To get started:</strong>
                    <br>1. Select a model above
                    <br>2. Click "Load Model" 
                    <br>3. Wait for download to complete
                    <br>4. Start chatting!
                </div>
            </div>
            
            <div class="loading-indicator" id="loadingIndicator">
                <div class="dots">
                    <div class="dot"></div>
                    <div class="dot"></div>
                    <div class="dot"></div>
                </div>
            </div>
        </div>
        
        <div class="input-area">
            <div class="input-container">
                <input 
                    type="text" 
                    id="messageInput" 
                    placeholder="Load a model first to start chatting..." 
                    disabled
                >
                <button id="sendButton" disabled>Send</button>
            </div>
        </div>
    </div>

    <script type="module">
        // Import WebLLM from CDN
        import * as webllm from "https://esm.run/@mlc-ai/web-llm";

        class StaticWebLLMChat {
            constructor() {
                this.engine = null;
                this.isLoading = false;
                this.conversationHistory = [];
                this.initializeElements();
                this.setupEventListeners();
            }

            initializeElements() {
                this.statusEl = document.getElementById('status');
                this.messagesEl = document.getElementById('messages');
                this.messageInput = document.getElementById('messageInput');
                this.sendButton = document.getElementById('sendButton');
                this.loadingIndicator = document.getElementById('loadingIndicator');
                this.modelSelect = document.getElementById('modelSelect');
                this.loadModelBtn = document.getElementById('loadModelBtn');
            }

            setupEventListeners() {
                this.loadModelBtn.addEventListener('click', () => this.initializeWebLLM());
                this.sendButton.addEventListener('click', () => this.sendMessage());
                this.messageInput.addEventListener('keypress', (e) => {
                    if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        this.sendMessage();
                    }
                });
            }

            updateStatus(message, type = 'loading') {
                this.statusEl.textContent = message;
                this.statusEl.className = `status ${type}`;
            }

            async initializeWebLLM() {
                const selectedModel = this.modelSelect.value;
                
                try {
                    this.updateStatus('Initializing WebLLM engine...', 'loading');
                    this.loadModelBtn.disabled = true;
                    this.modelSelect.disabled = true;
                    
                    // Create new engine instance
                    this.engine = new webllm.MLCEngine();
                    
                    // Load the selected model with progress callback
                    await this.engine.reload(selectedModel, {
                        progress_callback: (progress) => {
                            const percent = Math.round(progress * 100);
                            this.updateStatus(`Loading ${selectedModel}: ${percent}%`, 'loading');
                        }
                    });

                    this.updateStatus(`‚úÖ ${selectedModel} loaded successfully!`, 'ready');
                    this.messageInput.disabled = false;
                    this.sendButton.disabled = false;
                    this.messageInput.placeholder = 'Type your message here...';
                    this.messageInput.focus();

                    // Add welcome message
                    this.addMessage('üéâ Great! I\'m now ready to chat. What would you like to talk about?', 'assistant');

                } catch (error) {
                    console.error('Failed to initialize WebLLM:', error);
                    this.updateStatus(`‚ùå Error: ${error.message}`, 'error');
                    this.loadModelBtn.disabled = false;
                    this.modelSelect.disabled = false;
                    
                    // Add error message to chat
                    this.addMessage(`Sorry, I couldn't load the model. Error: ${error.message}. Please try refreshing the page or selecting a different model.`, 'assistant');
                }
            }

            addMessage(content, role) {
                const messageEl = document.createElement('div');
                messageEl.className = `message ${role}`;
                
                // Simple markdown-like formatting
                const formattedContent = content
                    .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
                    .replace(/\*(.*?)\*/g, '<em>$1</em>')
                    .replace(/\n/g, '<br>');
                
                messageEl.innerHTML = formattedContent;
                this.messagesEl.appendChild(messageEl);
                this.messagesEl.scrollTop = this.messagesEl.scrollHeight;
                
                // Store in conversation history
                this.conversationHistory.push({ role, content });
                
                // Keep conversation history manageable (last 10 exchanges)
                if (this.conversationHistory.length > 20) {
                    this.conversationHistory = this.conversationHistory.slice(-20);
                }
            }

            showLoading(show) {
                this.loadingIndicator.style.display = show ? 'block' : 'none';
                if (show) {
                    this.messagesEl.scrollTop = this.messagesEl.scrollHeight;
                }
            }

            async sendMessage() {
                if (!this.engine || this.isLoading || !this.messageInput.value.trim()) {
                    return;
                }

                const userMessage = this.messageInput.value.trim();
                this.messageInput.value = '';
                this.isLoading = true;
                this.sendButton.disabled = true;
                this.messageInput.disabled = true;

                // Add user message to chat
                this.addMessage(userMessage, 'user');
                this.showLoading(true);

                try {
                    // Prepare conversation context (last few messages)
                    const messages = this.conversationHistory.slice(-10);
                    
                    // Create chat completion
                    const completion = await this.engine.chat.completions.create({
                        messages: messages,
                        temperature: 0.8,
                        max_tokens: 1024,
                        top_p: 0.9,
                    });

                    const assistantMessage = completion.choices[0].message.content;
                    this.showLoading(false);
                    this.addMessage(assistantMessage, 'assistant');

                } catch (error) {
                    console.error('Error generating response:', error);
                    this.showLoading(false);
                    this.addMessage('Sorry, I encountered an error generating a response. Please try again or refresh the page if the problem persists.', 'assistant');
                } finally {
                    this.isLoading = false;
                    this.sendButton.disabled = false;
                    this.messageInput.disabled = false;
                    this.messageInput.focus();
                }
            }
        }

        // Initialize the chat app when DOM is loaded
        document.addEventListener('DOMContentLoaded', () => {
            new StaticWebLLMChat();
        });

        // Initialize immediately if DOM is already loaded
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', () => {
                new StaticWebLLMChat();
            });
        } else {
            new StaticWebLLMChat();
        }
    </script>
</body>
</html>